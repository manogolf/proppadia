name: NHL Daily (Ingest → Refresh → Score → Export)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "15 10 * * *" # ~03:15 PT daily, after games finalize

concurrency:
  group: nhl-daily
  cancel-in-progress: false

jobs:
  daily:
    runs-on: ubuntu-latest
    env:
      # Required repo secrets:
      # - SUPABASE_DB_URL: postgres connection string (pooled OK)
      # - SUPABASE_URL:    https://<project>.supabase.co
      # - SUPABASE_SERVICE_ROLE_KEY: service role key
      DATABASE_URL: ${{ secrets.SUPABASE_DB_URL }}
      SUPABASE_DB_URL: ${{ secrets.SUPABASE_DB_URL }}
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      TZ: UTC

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set dates (yesterday in UTC)
        run: |
          echo "DATE=$(date -u +%F)" >> $GITHUB_ENV
          echo "YDAY=$(date -u -d 'yesterday' +%F)" >> $GITHUB_ENV
          echo "Dates -> DATE=${DATE} YDAY=${YDAY}"

      - name: Install psql client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Check DB connectivity
        run: psql "$SUPABASE_DB_URL" -v ON_ERROR_STOP=1 -c "SELECT now();"

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Python deps for scripts
        run: |
          python -m pip install --upgrade pip
          # Training/runtime libs for scripts (avoid backend FastAPI deps)
          python -m pip install -r nhl/training/requirements.txt
          python -m pip install "psycopg[binary]>=3.1" "requests>=2.31"

      # ─── Transform (refresh features/views) ────────────────────────────────────
      - name: Refresh features/views (refresh.sql)
        run: |
          SQL_PATH="nhl/scripts/refresh.sql"
          ls -l "$SQL_PATH"
          psql "$SUPABASE_DB_URL" -v ON_ERROR_STOP=1 -f "$SQL_PATH"

      - name: Pre-export training feature CSVs for scorer
        run: |
          # avoid timeouts for heavy \COPY
          export PGOPTIONS='-c statement_timeout=0'
          mkdir -p exports

          # SOG: only today's rows (fast)
          psql "$SUPABASE_DB_URL" -v ON_ERROR_STOP=1 -c "\COPY (
            SELECT * FROM nhl.export_training_nhl_sog_v2
            WHERE game_date = '${DATE}'::date
            ORDER BY game_date, player_id
          ) TO STDOUT WITH CSV HEADER" > exports/train_nhl_sog_v2.csv

          # Goalie: wide schema; synthesize a few expected cols; today's rows
          psql "$SUPABASE_DB_URL" -v ON_ERROR_STOP=1 -c "\COPY (
            SELECT
              player_id, game_id, team_id, opponent_id, is_home, game_date,
              1.0::numeric                                AS start_prob,
              COALESCE(d5_saves_per60, 0)::numeric        AS d5_saves_per60,
              COALESCE(d10_saves_per60, 0)::numeric       AS d10_saves_per60,
              0::numeric                                  AS d20_saves_per60,
              COALESCE(d5_shots_faced_per60, 0)::numeric  AS d5_shots_faced_per60,
              COALESCE(d10_shots_faced_per60, 0)::numeric AS d10_shots_faced_per60,
              COALESCE(season_save_pct, 0)::numeric       AS season_save_pct,
              COALESCE(team_d10_sf_per_game, 0)::numeric  AS team_d10_sf_per_game,
              COALESCE(opp_d10_sf_allowed_per_game, 0)::numeric AS opp_d10_sf_allowed_per_game,
              COALESCE(team_d10_sa_per60, 0)::numeric     AS team_d10_sa_per60,
              COALESCE(opp_d10_sf_per60, 0)::numeric      AS opp_d10_sf_per60,
              0::numeric                                  AS team_d10_sf_per60,
              0::numeric                                  AS opp_d10_sa_per60,
              COALESCE(pace_index, 0)::numeric            AS pace_index,
              COALESCE(pace_matchup_index, 0)::numeric    AS pace_matchup_index,
              COALESCE(rest_days, 0)::smallint            AS rest_days,
              COALESCE(b2b_flag, false)                   AS b2b_flag
            FROM nhl.training_features_goalie_saves_v2
            WHERE game_date = '${DATE}'::date
          ) TO STDOUT WITH CSV HEADER" > exports/train_goalie_saves_v2.csv

          ls -lh exports/

      # ─── Ingest/Score orchestration (uses the pre-exported CSVs) ──────────────
      - name: Ingest/Score (run_daily_slate.py)
        run: |
          python nhl/scripts/run_daily_slate.py \
            --project nhl \
            --sog-csv exports/train_nhl_sog_v2.csv \
            --saves-csv exports/train_goalie_saves_v2.csv \
            --db-url "$SUPABASE_DB_URL"

      # ─── Score predictions for today's slate (redundant) ─────────────────────
      - name: Score props (today) — handled in run_daily_slate
        run: |
          echo "Skipped: already scored inside nhl/scripts/run_daily_slate.py"
          ls -lh nhl/data/processed/sog_predictions.csv || true
          ls -lh nhl/data/processed/saves_predictions.csv || true

      - name: Load predictions to DB
        run: |
          if [ -f nhl/scripts/load_predictions_to_db.py ]; then
            python nhl/scripts/load_predictions_to_db.py \
              --project nhl \
              --db-url "$SUPABASE_DB_URL" \
              --sog-csv nhl/data/processed/sog_predictions.csv \
              --saves-csv nhl/data/processed/saves_predictions.csv
          else
            echo "No separate loader; predictions remain as CSVs."
          fi

      # ─── Quick sanity counts (optional) ───────────────────────────────────────
      - name: Verify counts (preseason-friendly)
        run: |
          psql "$SUPABASE_DB_URL" -v ON_ERROR_STOP=1 -v DATE="$DATE" -c "
            WITH g AS (
              SELECT game_id FROM nhl.games WHERE game_date = :'DATE'::date
            )
            SELECT 'games_today' AS which, COUNT(*) AS n
            FROM nhl.games WHERE game_date = :'DATE'::date
            UNION ALL
            SELECT 'skater_logs_today', COUNT(*)
            FROM nhl.skater_game_logs_raw WHERE game_date = :'DATE'::date
            UNION ALL
            SELECT 'goalie_logs_today', COUNT(*)
            FROM nhl.goalie_game_logs_raw WHERE game_date = :'DATE'::date
            UNION ALL
            SELECT 'features_sog_today', COUNT(*)
            FROM nhl.training_features_nhl_sog_v2 WHERE game_date = :'DATE'::date
            UNION ALL
            SELECT 'features_goalie_today', COUNT(*)
            FROM nhl.training_features_goalie_saves_v2 WHERE game_date = :'DATE'::date
            UNION ALL
            SELECT 'sog_stage_rows', COUNT(*)
            FROM nhl.predictions_sog_stage s WHERE EXISTS (SELECT 1 FROM g WHERE g.game_id = s.game_id)
            UNION ALL
            SELECT 'saves_stage_rows', COUNT(*)
            FROM nhl.predictions_saves_stage s WHERE EXISTS (SELECT 1 FROM g WHERE g.game_id = s.game_id)
            UNION ALL
            SELECT 'predictions_today', COUNT(*)
            FROM nhl.predictions p WHERE EXISTS (SELECT 1 FROM g WHERE g.game_id = p.game_id)
          ;"

      # ─── Upload artifacts (CSV snapshots) ─────────────────────────────────────
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: nhl-exports-${{ env.DATE }}
          path: |
            exports/train_nhl_sog_v2.csv
            exports/train_goalie_saves_v2.csv
          if-no-files-found: warn
          retention-days: 14
